{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wiki-topcats-reduced.txt', sep='\\t', header = None)\n",
    "df.columns = ['from', 'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes = 461193\n"
     ]
    }
   ],
   "source": [
    "#vertexes\n",
    "fr = df.groupby('from').count()\n",
    "to = df.groupby('to').count()\n",
    "V = set(list(fr.index) + list(to.index))\n",
    "print('Number of nodes =', len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from       to\n",
      "0    52   401135\n",
      "1    52  1069112\n",
      "2    52  1163551 \n",
      "\n",
      "          from      to\n",
      "361754  401135   60219\n",
      "361755  401135  167532\n",
      "361756  401135  400980\n",
      "361757  401135  401018\n",
      "361758  401135  401019\n"
     ]
    }
   ],
   "source": [
    "#directed cause these two are different\n",
    "print(df[df['from'] ==52], '\\n')\n",
    "print(df[df['from'] ==401135].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 2645247\n"
     ]
    }
   ],
   "source": [
    "print('Number of edges:',len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average degree of the vertex is: 5.735661642739591\n"
     ]
    }
   ],
   "source": [
    "print('The average degree of the vertex is:', len(df.index)/len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = open('wiki-topcats-categories.txt', 'r')\n",
    "categories = {}\n",
    "for line in o :\n",
    "    line = line.replace('\\n','')\n",
    "    l = line.split(' ')\n",
    "    l[0] = l[0].replace('Category:', '').replace(';','')\n",
    "    try:\n",
    "        #print(len(l[1:]))\n",
    "        if len(l[1:])>=3500:\n",
    "            categories[l[0]] = list(map(int, l[1:]))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_category = list(categories.keys())[7]\n",
    "len(categories[input_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.from_pandas_edgelist(df, 'from', 'to', create_using=nx.DiGraph )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dijkstra:\n",
    "\n",
    "    def dijkstra(self, dic, dist):\n",
    "        node = list(dic.keys())[0]\n",
    "        actual_dist = list(dic.values())[0]\n",
    "        try:\n",
    "            l = [list(self.graph[node]),1]\n",
    "            while len(l[0]) > 0:\n",
    "                dist = l[1]\n",
    "                for i in l[0]:\n",
    "                    m = []\n",
    "                    if (i in self.visited):\n",
    "                        if self.actual_node in self.visited[i]:\n",
    "                            if (self.visited[i][self.actual_node] > dist):\n",
    "                                self.visited[i][self.actual_node] = dist\n",
    "                        else:\n",
    "                            self.visited[i][self.actual_node] = dist\n",
    "\n",
    "                    elif (self.unvisited[i] == -1):\n",
    "                        del self.unvisited[i]\n",
    "                        self.visited[i] = {self.actual_node:dist}\n",
    "\n",
    "                    for j in list(self.graph[i]):\n",
    "                        if (not(j in self.visited)):\n",
    "                            m.append(j)\n",
    "                        elif not(self.actual_node in self.visited[j]):\n",
    "                            m.append(j)\n",
    "                l = [m,dist+1]\n",
    "        except:\n",
    "            pass       \n",
    "        \n",
    "    \n",
    "    def __init__(self, graph, categories, input_category):\n",
    "        \n",
    "        self.graph = graph\n",
    "        self.nodes = categories\n",
    "        self.initial = categories[input_category]\n",
    "        self.unvisited = {}\n",
    "        for i in self.graph.nodes:\n",
    "            self.unvisited[i] = -1\n",
    "        self.visited = {}\n",
    "        self.l = []\n",
    "        idx = 1\n",
    "        for i in self.initial:\n",
    "            idx+=1\n",
    "            self.actual_node = i\n",
    "            self.visited[i] = {self.actual_node: 0}\n",
    "            try:\n",
    "                del self.unvisited[i]\n",
    "            except:\n",
    "                pass\n",
    "            self.dijkstra({self.actual_node:0},1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dij = Dijkstra(DG, categories, input_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = {}\n",
    "set_of_visited = set(list(dij.visited.keys()))\n",
    "for i in categories:\n",
    "    if i != input_category:\n",
    "        shortest_path=[]\n",
    "        s = set(categories[i]).intersection(set_of_visited)\n",
    "        if len(s)> 0:\n",
    "            for j in s:\n",
    "                shortest_path += (list(dij.visited[j].values()))\n",
    "            median[i] = np.median(shortest_path)\n",
    "        else:\n",
    "            median[i] = 100**100\n",
    "median[input_category] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Year_of_birth_unknown', -1),\n",
       "             ('Year_of_death_missing', 2.0),\n",
       "             ('Year_of_birth_missing', 2.0),\n",
       "             ('English_footballers', 3.0),\n",
       "             ('Association_football_forwards', 3.0),\n",
       "             ('Association_football_goalkeepers', 3.0),\n",
       "             ('Association_football_midfielders', 3.0),\n",
       "             ('Association_football_defenders', 3.0),\n",
       "             ('Indian_films', 3.0),\n",
       "             ('English_cricketers', 3.0),\n",
       "             ('Rivers_of_Romania', 3.0),\n",
       "             ('British_films', 3.0),\n",
       "             ('The_Football_League_players', 4.0),\n",
       "             ('Article_Feedback_Pilot', 4.0),\n",
       "             ('Fellows_of_the_Royal_Society', 5.0),\n",
       "             ('Members_of_the_United_Kingdom_Parliament_for_English_constituencies',\n",
       "              6.0),\n",
       "             ('Black-and-white_films', 6.0),\n",
       "             ('Harvard_University_alumni', 7.0),\n",
       "             ('People_from_New_York_City', 7.0),\n",
       "             ('American_military_personnel_of_World_War_II', 7.0),\n",
       "             ('Main_Belt_asteroids', 8.0),\n",
       "             ('Asteroids_named_for_people', 8.0),\n",
       "             ('English-language_films', 8.0),\n",
       "             ('American_films', 8.0),\n",
       "             ('American_Jews', 8.0),\n",
       "             ('Living_people', 9.0),\n",
       "             ('Year_of_birth_missing_(living_people)', 10.0),\n",
       "             ('Major_League_Baseball_pitchers', 11.0),\n",
       "             ('American_television_actors', 11.0),\n",
       "             ('American_film_actors', 11.0),\n",
       "             ('Place_of_birth_missing_(living_people)', 11.0),\n",
       "             ('English_television_actors', 14.0),\n",
       "             ('Windows_games', 22.0),\n",
       "             ('Debut_albums', 24.0),\n",
       "             ('English-language_albums', 25.0)])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_ranking = OrderedDict()\n",
    "block_ranking = OrderedDict(sorted(median.items(), key=lambda x: x[1]))\n",
    "block_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each article to the categories it is present\n",
    "\n",
    "articles = {}\n",
    "for name in categories:\n",
    "    for article in categories[name]:\n",
    "        if article in articles:\n",
    "            articles[article].append(name)\n",
    "        else:\n",
    "            articles[article] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an article belongs to multiple categories, choose one according to block_ranking\n",
    "\n",
    "for article in articles:\n",
    "    if len(articles[article]) > 1:\n",
    "        minimum = ''\n",
    "        for cat in articles[article]:\n",
    "            if (minimum == '') or (block_ranking[minimum] > block_ranking[cat]):\n",
    "                minimum = cat\n",
    "        articles[article] = [minimum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_after_ranking = {}\n",
    "\n",
    "for i in articles:\n",
    "    if articles[i][0] in categories_after_ranking:\n",
    "        categories_after_ranking[articles[i][0]] +=  [i]\n",
    "    else:\n",
    "        categories_after_ranking[articles[i][0]] =  [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_birth_unknown\n",
      "Rivers_of_Romania\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 2/35 [00:00<00:04,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article_Feedback_Pilot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                            | 3/35 [00:01<00:11,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English_footballers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▍                                                                         | 4/35 [00:01<00:10,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association_football_goalkeepers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▊                                                                       | 5/35 [00:01<00:08,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_Football_League_players\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████▏                                                                    | 6/35 [00:01<00:06,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main_Belt_asteroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 7/35 [00:01<00:06,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association_football_forwards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▉                                                                | 8/35 [00:02<00:05,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellows_of_the_Royal_Society\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▎                                                             | 9/35 [00:02<00:04,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard_University_alumni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                          | 10/35 [00:02<00:05,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association_football_midfielders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:02<00:04,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_birth_missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████                                                      | 12/35 [00:02<00:03,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_military_personnel_of_World_War_II\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:02<00:04,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_Jews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:03<00:04,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asteroids_named_for_people\n",
      "Association_football_defenders\n",
      "English_television_actors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:03<00:03,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People_from_New_York_City\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:03<00:04,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_death_missing\n",
      "Members_of_the_United_Kingdom_Parliament_for_English_constituencies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [00:04<00:03,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Living_people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [00:18<01:01,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English_cricketers\n",
      "Windows_games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [00:18<00:37,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_film_actors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [00:19<00:25,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_television_actors\n",
      "Year_of_birth_missing_(living_people)\n",
      "Place_of_birth_missing_(living_people)\n",
      "English-language_films\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [00:20<00:12,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British_films\n",
      "American_films\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [00:21<00:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian_films\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [00:21<00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-and-white_films\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [00:21<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English-language_albums\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [00:21<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut_albums\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [00:22<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major_League_Baseball_pitchers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:22<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# VERSIONE MODIFICATA\n",
    "# da quella di prima cambia come trovare gli archi adatti (jj)\n",
    "\n",
    "idx = 0\n",
    "jj = nx.to_dict_of_lists(DG)\n",
    "\n",
    "for name in tqdm(block_ranking):\n",
    "    print(name)\n",
    "    if idx == 0:\n",
    "        weight_dict = {}\n",
    "        boh = DG.subgraph(categories_after_ranking[name])\n",
    "        weight_dict[name] = {}\n",
    "        for i in (boh.in_degree):\n",
    "            for j in jj[i[0]]:\n",
    "                    DG[i[0]][j]['weight'] = i[1]\n",
    "            idx +=1\n",
    "        for  i in boh.in_degree:\n",
    "            weight_dict[name][i[0]] = i[1]\n",
    "    else:\n",
    "        try:\n",
    "            boh = DG.subgraph(categories_after_ranking[name])\n",
    "            weight_dict[name] = {}\n",
    "\n",
    "            for i in boh.in_degree:\n",
    "                cumsum = i[1]\n",
    "                for j in jj[i[0]]:\n",
    "                        try:\n",
    "                            cumsum+=(list(DG.edges[j,i[0]].values()))[0]\n",
    "                        except:\n",
    "                            pass\n",
    "                weight_dict[name][i[0]] = cumsum\n",
    "\n",
    "\n",
    "            for i in boh.in_degree:\n",
    "                for j in jj[i[0]]:\n",
    "                        DG[i[0]][j]['weight'] = weight_dict[name][i[0]]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank per ogni nodo (come nello step3 dell'homework)\n",
    "rank = []\n",
    "for i in weight_dict:\n",
    "    rank += list(OrderedDict(sorted(weight_dict[i].items(), key=lambda x: x[1], reverse=True)).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSIONE VISTA INSIEME\n",
    "\n",
    "idx = 0\n",
    "for name in tqdm(block_ranking):\n",
    "    print(name)\n",
    "    if idx == 0:\n",
    "        weight_dict = {}\n",
    "        boh = DG.subgraph(categories_after_ranking[name])\n",
    "        weight_dict[name] = {}\n",
    "        for i in boh.in_degree:\n",
    "            print(idx)\n",
    "            for j in DG.edges:\n",
    "                if j[0] == i[0]:\n",
    "                    DG[i[0]][j[1]]['weight'] = i[1]\n",
    "            idx +=1\n",
    "        for i in boh.in_degree: \n",
    "            weight_dict[name][i[0]] = i[1]\n",
    "        \n",
    "\n",
    "        try:\n",
    "            boh = DG.subgraph(categories_after_ranking[name])\n",
    "            weight_dict[name] = {}\n",
    "\n",
    "            for i in boh.in_degree:\n",
    "                cumsum = i[1]\n",
    "                for j in DG.edges:\n",
    "                    if j[1] == i[0]:\n",
    "                        try:\n",
    "                            cumsum+=(list(DG.edges[j[0],j[1]].values()))[0]\n",
    "                        except:\n",
    "                            pass\n",
    "                weight_dict[name][i[0]] = cumsum\n",
    "\n",
    "\n",
    "            for i in boh.in_degree:\n",
    "                for j in DG.edges:\n",
    "                    if j[0] == i[0]:\n",
    "                        DG[i[0]][j[1]]['weight'] = weight_dict[name][i[0]]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "weight_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
